{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Deeplake dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Deep Lake dataset has been successfully created!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/taahasbajwa/test_dataset\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://taahasbajwa/test_dataset loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    }
   ],
   "source": [
    "import deeplake\n",
    "\n",
    "# env variable ACTIVELOOP_TOKEN must be set with your API token\n",
    "\n",
    "# create dataset on deeplake\n",
    "username = \"taahasbajwa\"\n",
    "dataset_name = \"test_dataset\"\n",
    "ds = deeplake.dataset(f\"hub://{username}/{dataset_name}\")\n",
    "\n",
    "# create column text\n",
    "ds.create_tensor('text', htype=\"text\")\n",
    "\n",
    "# add some texts to the dataset\n",
    "texts = [f\"text {i}\" for i in range(1, 11)]\n",
    "for text in texts:\n",
    "    ds.append({\"text\": text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'firstdbf9474d461a19e9333c2fd19b46115348f'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.commit(\"added texts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Data from Deeplake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Lake Data Loader for PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-21 13:32:55,330 | INFO | SingleProcessIterator initialized 6413\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.:   0%|          | 101/2.00G [00:00<2288:24:27, 261B/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Batch 0\n",
      "Sample 0: text 5\n",
      "Sample 1: text 9\n",
      "Sample 2: text 3\n",
      "\n",
      "Batch 1\n",
      "Sample 0: text 7\n",
      "Sample 1: text 6\n",
      "Sample 2: text 8\n",
      "\n",
      "Batch 2\n",
      "Sample 0: text 4\n",
      "Sample 1: text 10\n",
      "Sample 2: text 1\n",
      "\n",
      "Batch 3\n",
      "Sample 0: text 2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create PyTorch data loader\n",
    "batch_size = 3\n",
    "train_loader = ds.dataloader()\\\n",
    "    .batch(batch_size)\\\n",
    "    .shuffle()\\\n",
    "    .pytorch()\n",
    "\n",
    "# loop over the elements\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"Batch {i}\")\n",
    "    samples = batch.get(\"text\")\n",
    "    for j, sample in enumerate(samples):\n",
    "        print(f\"Sample {j}: {sample}\")\n",
    "    print()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Datasets and PyTorch Data Loaders using Deep Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class DeepLakePyTorchDataset(Dataset):\n",
    "    def __init__(self, ds):\n",
    "        self.ds = ds\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        texts = self.ds.text[idx].text().astype(str)\n",
    "        return { \"text\": texts }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0\n",
      "Sample 0: text 10\n",
      "Sample 1: text 7\n",
      "Sample 2: text 8\n",
      "\n",
      "Batch 1\n",
      "Sample 0: text 3\n",
      "Sample 1: text 1\n",
      "Sample 2: text 5\n",
      "\n",
      "Batch 2\n",
      "Sample 0: text 6\n",
      "Sample 1: text 2\n",
      "Sample 2: text 4\n",
      "\n",
      "Batch 3\n",
      "Sample 0: text 9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create PyTorch dataset\n",
    "ds_pt = DeepLakePyTorchDataset(ds)\n",
    "\n",
    "# create PyTorch data loader from PyTorch dataset\n",
    "dataloader_pytorch = DataLoader(ds_pt, batch_size=3, shuffle=True)\n",
    "\n",
    "# loop over the elements\n",
    "for i, batch in enumerate(dataloader_pytorch):\n",
    "    print(f\"Batch {i}\")\n",
    "    samples = batch.get(\"text\")\n",
    "    for j, sample in enumerate(samples):\n",
    "        print(f\"Sample {j}: {sample}\")\n",
    "    print()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering and Querying datasets (to get high quality data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-21 13:43:12,555 | INFO | SingleProcessIterator initialized 6413\n",
      "\n",
      "2023-10-21 13:43:12,555 | INFO | SingleProcessIterator initialized 6413\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Please wait, filling up the shuffle buffer with samples.:   0%|          | 21.0/2.00G [00:00<60:29:06, 9.86kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffle buffer filling is complete.\n",
      "Batch 0\n",
      "Sample 0: text 1\n",
      "Sample 1: text 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ds_view = ds.query(\"select * where contains(text, '1')\")\n",
    "\n",
    "# code that creates a data loader and prints the batches\n",
    "# create PyTorch data loader\n",
    "batch_size = 3\n",
    "train_loader = ds_view.dataloader()\\\n",
    "    .batch(batch_size)\\\n",
    "    .shuffle()\\\n",
    "    .pytorch()\n",
    "\n",
    "# loop over the elements\n",
    "for i, batch in enumerate(train_loader):\n",
    "    print(f\"Batch {i}\")\n",
    "    samples = batch.get(\"text\")\n",
    "    for j, sample in enumerate(samples):\n",
    "        print(f\"Sample {j}: {sample}\")\n",
    "    print()\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  7.43it/s]\n",
      " \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hub://taahasbajwa/test_dataset/.queries/strings_with_1'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the filtered dataset\n",
    "ds_view.save_view(id=\"strings_with_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/taahasbajwa/test_dataset?view=strings_with_1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://taahasbajwa/test_dataset/.queries/strings_with_1 loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "ds = deeplake.dataset(\"hub://taahasbajwa/test_dataset/.queries/strings_with_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envllmops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
